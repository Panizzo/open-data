{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as os\n",
    "import requests as req\n",
    "import zipfile as zipfile\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_directories():\n",
    "    \"\"\"\n",
    "    Funcao de criacao das pastas para armazenamento dos dados, caso nao existam.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Diretorios para armazenamento dos dados coletados\n",
    "    directories = ['..\\\\data\\\\01-collected'\n",
    "                  ,'..\\\\data\\\\02-cleaned'\n",
    "                  ,'..\\\\data\\\\03-organized'\n",
    "                  ,'..\\\\data\\\\04-standardized']\n",
    "    \n",
    "    # Log: Mensagem de inicio da criacao dos diretorios\n",
    "    print(str(datetime.now()) + ': Criacao dos diretorios para armazenamento dos dados iniciada.')\n",
    "    \n",
    "    # Para cada diretorio na lista de diretorios\n",
    "    for directory in directories:\n",
    "        \n",
    "        # Verifica se o diretorio existe\n",
    "        if not os.path.exists(directory):\n",
    "            \n",
    "            # Cria o diretorio\n",
    "            os.makedirs(directory)\n",
    "            \n",
    "            # Log: Mensagem de criacao do diretorio\n",
    "            print(str(datetime.now()) + ': Diretorio ' + directory + ' criado.')\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            # Log: Mensagem de diretorio existente\n",
    "            print(str(datetime.now()) + ': Diretorio ' + directory + ' ja existe.')\n",
    "    \n",
    "    # Log: Mensagem de fim da criacao dos diretorios\n",
    "    print(str(datetime.now()) + ': Criacao dos diretorios para armazenamento dos dados finalizada.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(**kwargs):\n",
    "    \"\"\"\n",
    "    Funcao que realiza o download do arquivo. Ao final do download, e verificado\n",
    "    se o arquivo solicitado esta vazio. Caso esteja vazio, o arquivo e apagado. Caso contrario,\n",
    "    o arquivo e descompactado.\n",
    "    \n",
    "    Args:\n",
    "        url_query (str): URL parametrizada para download do arquivo.\n",
    "        download_path (str): Caminho do diretorio onde sera salvo o arquivo.\n",
    "        download_directory (str): Caminho do diretorio para decompactacao do arquivo\n",
    "    \"\"\"\n",
    "    \n",
    "    # Log: Mensagem de inicio do download do arquivo\n",
    "    print(str(datetime.now()) + ': Inicio do download do arquivo ' + kwargs['download_path'])\n",
    "    \n",
    "    # Prepara a requisicao de download do arquivo\n",
    "    res = req.get(kwargs['url_query'], stream = True)\n",
    "    \n",
    "    # Se for encontrada a URL para download\n",
    "    if res.status_code == 200:\n",
    "        \n",
    "        # Faz o download do arquivo\n",
    "        with open(kwargs['download_path'], 'wb') as f:\n",
    "            \n",
    "            # Log: Mensagem de URL encontrada e de inicio do download\n",
    "            print(str(datetime.now()) + ': URL encontrada, fazendo o download do arquivo: ' + kwargs['download_path'])\n",
    "            \n",
    "            # Download do arquivo em pedacos\n",
    "            for chunk in res.iter_content(chunk_size = 1024):\n",
    "                f.write(chunk)\n",
    "        \n",
    "        # Verifica o tamanho do arquivo recebido\n",
    "        file_size = os.stat(kwargs['download_path']).st_size\n",
    "        \n",
    "        # Se o tamanho do arquivo for muito \n",
    "        # pequeno remove o arquivo da pasta \n",
    "        if file_size <= 100:\n",
    "            \n",
    "            # Log: Mensagem de remocao por arquivo por nao conter dados\n",
    "            print(str(datetime.now()) + ': Arquivo ' + kwargs['download_path'] + ' removido por conter poucos dados.')\n",
    "            \n",
    "            # Remove o arquivo sem dados\n",
    "            os.remove(kwargs['download_path'])\n",
    "            \n",
    "        # Caso contrario, descompacta o arquivo csv \n",
    "        # na pasta e remove o arquivo compactado\n",
    "        else:\n",
    "            \n",
    "            # Log: Mensagem de inicio da descompactacao do arquivo zip\n",
    "            print(str(datetime.now()) + ': Descompactando o arquivo ' + kwargs['download_path'])\n",
    "            \n",
    "            # Descompacta o arquivo zip mantem apenas o csv\n",
    "            zip_ref = zipfile.ZipFile(kwargs['download_path'], 'r')\n",
    "            zip_ref.extractall(path=kwargs['download_directory'])\n",
    "            zip_ref.close()\n",
    "            os.remove(kwargs['download_path'])\n",
    "            \n",
    "            # log: Mensagem de finalizacao do download do arquivo\n",
    "            print(str(datetime.now()) + ': Fim do download do arquivo ' + kwargs['download_path'])\n",
    "            \n",
    "    else:\n",
    "        print(str(datetime.now()) + ': Nao foram encontrados arquivos referentes ao ano de ' + kwargs['file_date_ref'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data(**kwargs):\n",
    "    \"\"\"\n",
    "    Coleta os dados para cada ano de referencia dentro das datas de inicio e fim informadas.\n",
    "    \n",
    "    Args:\n",
    "        dt_ini_ref (date): Data inicial para coleta dos dados\n",
    "        dt_fim_ref (date): Data final para coleta dos dados\n",
    "    \"\"\"\n",
    "    \n",
    "    # Cria os diretorios para armazenamento dos dados\n",
    "    data_directories()\n",
    "    \n",
    "    # Define o diretorio para download dos arquivos\n",
    "    kwargs['download_directory'] = '..\\\\data\\\\01-collected\\\\'\n",
    "    \n",
    "    # Define a URL base de busca dos arquivos para download\n",
    "    kwargs['download_url'] = 'http://arquivos.prf.gov.br/arquivos/index.php/s/'\n",
    "    \n",
    "    # Define o nome e extensao do arquivo para download\n",
    "    kwargs['file_names'] = ['jdDLrQIf33xXSCe'  # Referente a 2020\n",
    "                           ,'kRBUylqz6DyQznN'  # Referente a 2019\n",
    "                           ,'MaC6cieXSFACNWT'  # Referente a 2018\n",
    "                           ,'nqvFu7xEF6HhbAq'  # Referente a 2017\n",
    "                           ] \n",
    "    kwargs['file_ext'] = '.zip'\n",
    "    \n",
    "    # Log: Mensagem de inicio do processo \n",
    "    print(str(datetime.now()) + ': Coleta dos arquivos iniciada.')\n",
    "       \n",
    "    # Para cada mes de referencia dentro das datas de inicio e fim\n",
    "    for file in kwargs['file_names']:\n",
    "        \n",
    "        # Prepara as variaveis do mes de referencia\n",
    "        kwargs['download_file'] = file + kwargs['file_ext']\n",
    "        \n",
    "        # Define a URL completa para download do arquivo\n",
    "        kwargs['url_query'] = kwargs['download_url'] + file + '/download'\n",
    "        \n",
    "        # Define o caminho completo para armazenamento do arquivo de download\n",
    "        kwargs['download_path'] = kwargs['download_directory'] + kwargs['download_file']\n",
    "        \n",
    "        # Inicia o download do arquivo\n",
    "        download_file(**kwargs)\n",
    "    \n",
    "    # Log: Mensagem de inicio da remocao de arquivos nao relacionados com os dados\n",
    "    print(str(datetime.now()) + ': Verificando a existencia de arquivos nao relacionados com os dados.')\n",
    "    \n",
    "    # Remove arquivos nao relacionados com os dados (Ex.: leiame.pdf)\n",
    "    downloaded_files = os.listdir(kwargs['download_directory'])\n",
    "    unrelated_files = [file for file in downloaded_files if file.endswith('.pdf')]\n",
    "    for file in unrelated_files:\n",
    "        file_to_remove = os.path.join(kwargs['download_directory'], file)\n",
    "        os.remove(file_to_remove)\n",
    "        \n",
    "        # Log: Mensagem de remocao de arquivo nao relacionado com os dados\n",
    "        print(str(datetime.now()) + ': Arquivo ' + file_to_remove + ' removido.')\n",
    "        \n",
    "    # Log: Mensagem de fim da remocao de arquivos nao relacionados com os dados\n",
    "    print(str(datetime.now()) + ': Remocao dos arquivos nao relacionados com os dados concluida.')\n",
    "\n",
    "    # Log: Mensagem de finalizacao do processo \n",
    "    print(str(datetime.now()) + ': Coleta dos arquivos finalizada.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-30 21:28:40.015309: Criacao dos diretorios para armazenamento dos dados iniciada.\n",
      "2021-05-30 21:28:40.016306: Diretorio ..\\data\\01-collected ja existe.\n",
      "2021-05-30 21:28:40.016306: Diretorio ..\\data\\02-cleaned ja existe.\n",
      "2021-05-30 21:28:40.016306: Diretorio ..\\data\\03-organized ja existe.\n",
      "2021-05-30 21:28:40.016306: Diretorio ..\\data\\04-standardized ja existe.\n",
      "2021-05-30 21:28:40.017304: Criacao dos diretorios para armazenamento dos dados finalizada.\n",
      "2021-05-30 21:28:40.017304: Coleta dos arquivos iniciada.\n",
      "2021-05-30 21:28:40.017304: Inicio do download do arquivo ..\\data\\01-collected\\jdDLrQIf33xXSCe.zip\n",
      "2021-05-30 21:28:40.298118: URL encontrada, fazendo o download do arquivo: ..\\data\\01-collected\\jdDLrQIf33xXSCe.zip\n",
      "2021-05-30 21:28:40.633190: Descompactando o arquivo ..\\data\\01-collected\\jdDLrQIf33xXSCe.zip\n",
      "2021-05-30 21:28:40.717693: Fim do download do arquivo ..\\data\\01-collected\\jdDLrQIf33xXSCe.zip\n",
      "2021-05-30 21:28:40.718659: Inicio do download do arquivo ..\\data\\01-collected\\kRBUylqz6DyQznN.zip\n",
      "2021-05-30 21:28:40.956394: URL encontrada, fazendo o download do arquivo: ..\\data\\01-collected\\kRBUylqz6DyQznN.zip\n",
      "2021-05-30 21:28:41.360641: Descompactando o arquivo ..\\data\\01-collected\\kRBUylqz6DyQznN.zip\n",
      "2021-05-30 21:28:41.452467: Fim do download do arquivo ..\\data\\01-collected\\kRBUylqz6DyQznN.zip\n",
      "2021-05-30 21:28:41.452467: Inicio do download do arquivo ..\\data\\01-collected\\MaC6cieXSFACNWT.zip\n",
      "2021-05-30 21:28:41.709859: URL encontrada, fazendo o download do arquivo: ..\\data\\01-collected\\MaC6cieXSFACNWT.zip\n",
      "2021-05-30 21:28:42.494102: Descompactando o arquivo ..\\data\\01-collected\\MaC6cieXSFACNWT.zip\n",
      "2021-05-30 21:28:42.587850: Fim do download do arquivo ..\\data\\01-collected\\MaC6cieXSFACNWT.zip\n",
      "2021-05-30 21:28:42.587850: Inicio do download do arquivo ..\\data\\01-collected\\nqvFu7xEF6HhbAq.zip\n",
      "2021-05-30 21:28:42.842960: URL encontrada, fazendo o download do arquivo: ..\\data\\01-collected\\nqvFu7xEF6HhbAq.zip\n",
      "2021-05-30 21:28:43.444564: Descompactando o arquivo ..\\data\\01-collected\\nqvFu7xEF6HhbAq.zip\n",
      "2021-05-30 21:28:43.555218: Fim do download do arquivo ..\\data\\01-collected\\nqvFu7xEF6HhbAq.zip\n",
      "2021-05-30 21:28:43.555218: Verificando a existencia de arquivos nao relacionados com os dados.\n",
      "2021-05-30 21:28:43.555218: Remocao dos arquivos nao relacionados com os dados concluida.\n",
      "2021-05-30 21:28:43.555218: Coleta dos arquivos finalizada.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Coleta os dados de acidentes por ocorrencia nas rodovias federais. \n",
    "    Origem: Policia Rodoviaria Federal (PRF)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepara o dicionario de variaveis (kwargs = keyworded arguments)\n",
    "    kwargs = {}\n",
    "    \n",
    "    # Coleta os arquivos\n",
    "    collect_data(**kwargs)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
