{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as os\n",
    "import requests as req\n",
    "import zipfile as zipfile\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_directories():\n",
    "    \"\"\"\n",
    "    Funcao de criacao das pastas para armazenamento dos dados, caso nao existam.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Diretorios para armazenamento dos dados coletados\n",
    "    directories = ['..\\\\data\\\\01-collected'\n",
    "                  ,'..\\\\data\\\\02-cleaned'\n",
    "                  ,'..\\\\data\\\\03-organized'\n",
    "                  ,'..\\\\data\\\\04-standardized']\n",
    "    \n",
    "    # Log: Mensagem de inicio da criacao dos diretorios\n",
    "    print(str(datetime.now()) + ': Criacao dos diretorios para armazenamento dos dados iniciada.')\n",
    "    \n",
    "    # Para cada diretorio na lista de diretorios\n",
    "    for directory in directories:\n",
    "        \n",
    "        # Verifica se o diretorio existe\n",
    "        if not os.path.exists(directory):\n",
    "            \n",
    "            # Cria o diretorio\n",
    "            os.makedirs(directory)\n",
    "            \n",
    "            # Log: Mensagem de criacao do diretorio\n",
    "            print(str(datetime.now()) + ': Diretorio ' + directory + ' criado.')\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            # Log: Mensagem de diretorio existente\n",
    "            print(str(datetime.now()) + ': Diretorio ' + directory + ' ja existe.')\n",
    "    \n",
    "    # Log: Mensagem de fim da criacao dos diretorios\n",
    "    print(str(datetime.now()) + ': Criacao dos diretorios para armazenamento dos dados finalizada.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(**kwargs):\n",
    "    \"\"\"\n",
    "    Funcao que realiza o download do arquivo. Ao final do download, e verificado\n",
    "    se o arquivo solicitado esta vazio. Caso esteja vazio, o arquivo e apagado. Caso contrario,\n",
    "    o arquivo e descompactado.\n",
    "    \n",
    "    Args:\n",
    "        url_query (str): URL parametrizada para download do arquivo.\n",
    "        download_path (str): Caminho do diretorio onde sera salvo o arquivo.\n",
    "        download_directory (str): Caminho do diretorio para decompactacao do arquivo\n",
    "    \"\"\"\n",
    "    \n",
    "    # Log: Mensagem de inicio do download do arquivo\n",
    "    print(str(datetime.now()) + ': Inicio do download do arquivo ' + kwargs['download_path'])\n",
    "    \n",
    "    # Prepara a requisicao de download do arquivo\n",
    "    res = req.get(kwargs['url_query'], stream = True)\n",
    "    \n",
    "    # Se for encontrada a URL para download\n",
    "    if res.status_code == 200:\n",
    "        \n",
    "        # Faz o download do arquivo\n",
    "        with open(kwargs['download_path'], 'wb') as f:\n",
    "            \n",
    "            # Log: Mensagem de URL encontrada e de inicio do download\n",
    "            print(str(datetime.now()) + ': URL encontrada, fazendo o download do arquivo: ' + kwargs['download_path'])\n",
    "            \n",
    "            # Download do arquivo em pedacos\n",
    "            for chunk in res.iter_content(chunk_size = 1024):\n",
    "                f.write(chunk)\n",
    "        \n",
    "        # Verifica o tamanho do arquivo recebido\n",
    "        file_size = os.stat(kwargs['download_path']).st_size\n",
    "        \n",
    "        # Se o tamanho do arquivo for muito \n",
    "        # pequeno remove o arquivo da pasta \n",
    "        if file_size <= 100:\n",
    "            \n",
    "            # Log: Mensagem de remocao por arquivo por nao conter dados\n",
    "            print(str(datetime.now()) + ': Arquivo ' + kwargs['download_path'] + ' removido por conter poucos dados.')\n",
    "            \n",
    "            # Remove o arquivo sem dados\n",
    "            os.remove(kwargs['download_path'])\n",
    "            \n",
    "        # Caso contrario, descompacta o arquivo csv \n",
    "        # na pasta e remove o arquivo compactado\n",
    "        else:\n",
    "            \n",
    "            # Log: Mensagem de inicio da descompactacao do arquivo zip\n",
    "            print(str(datetime.now()) + ': Descompactando o arquivo ' + kwargs['download_path'])\n",
    "            \n",
    "            # Descompacta o arquivo zip mantem apenas o csv\n",
    "            zip_ref = zipfile.ZipFile(kwargs['download_path'], 'r')\n",
    "            zip_ref.extractall(path=kwargs['download_directory'])\n",
    "            zip_ref.close()\n",
    "            os.remove(kwargs['download_path'])\n",
    "            \n",
    "            # log: Mensagem de finalizacao do download do arquivo\n",
    "            print(str(datetime.now()) + ': Fim do download do arquivo ' + kwargs['download_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data(**kwargs):\n",
    "    \"\"\"\n",
    "    Coleta os dados para cada mes de referencia dentro das datas de inicio e fim informadas.\n",
    "    \n",
    "    Args:\n",
    "        dt_ini_ref (date): Data inicial para coleta dos dados\n",
    "        dt_fim_ref (date): Data final para coleta dos dados\n",
    "    \"\"\"\n",
    "    \n",
    "    # Cria os diretorios para armazenamento dos dados\n",
    "    data_directories()\n",
    "    \n",
    "    # Define a data de referencia inicial\n",
    "    kwargs['dt_ref'] = kwargs['dt_ini_ref']\n",
    "    \n",
    "    # Define o diretorio para download dos arquivos\n",
    "    kwargs['download_directory'] = '..\\\\data\\\\01-collected\\\\'\n",
    "    \n",
    "    # Define a URL base de busca dos arquivos para download\n",
    "    kwargs['download_url'] = 'http://www.portaltransparencia.gov.br/download-de-dados/compras/'\n",
    "    \n",
    "    # Define o nome e extensao do arquivo para download\n",
    "    kwargs['file_name'] = '_Compras'\n",
    "    kwargs['file_ext'] = '.zip'\n",
    "    \n",
    "    # Log: Mensagem de inicio do processo \n",
    "    print(str(datetime.now()) + ': Coleta dos arquivos iniciada.')\n",
    "       \n",
    "    # Para cada mes de referencia dentro das datas de inicio e fim\n",
    "    while kwargs['dt_ref'] <= kwargs['dt_fim_ref']:\n",
    "        \n",
    "        # Prepara as variaveis do mes de referencia\n",
    "        kwargs['file_date_ref'] = kwargs['dt_ref'].strftime('%Y%m')\n",
    "        kwargs['download_file'] = kwargs['file_date_ref'] + kwargs['file_name'] + kwargs['file_ext']\n",
    "        \n",
    "        # Define a URL completa para download do arquivo\n",
    "        kwargs['url_query'] = kwargs['download_url'] + kwargs['file_date_ref']\n",
    "        \n",
    "        # Define o caminho completo para armazenamento do arquivo de download\n",
    "        kwargs['download_path'] = kwargs['download_directory'] + kwargs['download_file']\n",
    "        \n",
    "        # Inicia o download do arquivo\n",
    "        download_file(**kwargs)\n",
    "        \n",
    "        # Atualiza o mes de refencia\n",
    "        kwargs['dt_ref'] += relativedelta(months=1)\n",
    "\n",
    "    # Log: Mensagem de finalizacao do processo \n",
    "    print(str(datetime.now()) + ': Coleta dos arquivos finalizada.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-03 09:26:35.297996: Criacao dos diretorios para armazenamento dos dados iniciada.\n",
      "2020-01-03 09:26:35.300388: Diretorio ..\\data\\01-collected criado.\n",
      "2020-01-03 09:26:35.302948: Diretorio ..\\data\\02-cleaned criado.\n",
      "2020-01-03 09:26:35.305140: Diretorio ..\\data\\03-organized criado.\n",
      "2020-01-03 09:26:35.307933: Diretorio ..\\data\\04-standardized criado.\n",
      "2020-01-03 09:26:35.307933: Criacao dos diretorios para armazenamento dos dados finalizada.\n",
      "2020-01-03 09:26:35.307933: Coleta dos arquivos iniciada.\n",
      "2020-01-03 09:26:35.307933: Inicio do download do arquivo ..\\data\\01-collected\\201901_Compras.zip\n",
      "2020-01-03 09:26:37.438886: URL encontrada, fazendo o download do arquivo: ..\\data\\01-collected\\201901_Compras.zip\n",
      "2020-01-03 09:26:37.978185: Descompactando o arquivo ..\\data\\01-collected\\201901_Compras.zip\n",
      "2020-01-03 09:26:38.026182: Fim do download do arquivo ..\\data\\01-collected\\201901_Compras.zip\n",
      "2020-01-03 09:26:38.026320: Inicio do download do arquivo ..\\data\\01-collected\\201902_Compras.zip\n",
      "2020-01-03 09:26:39.976675: URL encontrada, fazendo o download do arquivo: ..\\data\\01-collected\\201902_Compras.zip\n",
      "2020-01-03 09:26:40.499716: Descompactando o arquivo ..\\data\\01-collected\\201902_Compras.zip\n",
      "2020-01-03 09:26:40.534178: Fim do download do arquivo ..\\data\\01-collected\\201902_Compras.zip\n",
      "2020-01-03 09:26:40.534497: Inicio do download do arquivo ..\\data\\01-collected\\201903_Compras.zip\n",
      "2020-01-03 09:26:42.103544: URL encontrada, fazendo o download do arquivo: ..\\data\\01-collected\\201903_Compras.zip\n",
      "2020-01-03 09:26:42.677552: Descompactando o arquivo ..\\data\\01-collected\\201903_Compras.zip\n",
      "2020-01-03 09:26:42.714393: Fim do download do arquivo ..\\data\\01-collected\\201903_Compras.zip\n",
      "2020-01-03 09:26:42.714393: Inicio do download do arquivo ..\\data\\01-collected\\201904_Compras.zip\n",
      "2020-01-03 09:26:44.214991: URL encontrada, fazendo o download do arquivo: ..\\data\\01-collected\\201904_Compras.zip\n",
      "2020-01-03 09:26:44.797430: Descompactando o arquivo ..\\data\\01-collected\\201904_Compras.zip\n",
      "2020-01-03 09:26:44.848701: Fim do download do arquivo ..\\data\\01-collected\\201904_Compras.zip\n",
      "2020-01-03 09:26:44.848701: Inicio do download do arquivo ..\\data\\01-collected\\201905_Compras.zip\n",
      "2020-01-03 09:26:46.394817: URL encontrada, fazendo o download do arquivo: ..\\data\\01-collected\\201905_Compras.zip\n",
      "2020-01-03 09:26:46.995042: Descompactando o arquivo ..\\data\\01-collected\\201905_Compras.zip\n",
      "2020-01-03 09:26:47.030944: Fim do download do arquivo ..\\data\\01-collected\\201905_Compras.zip\n",
      "2020-01-03 09:26:47.031942: Inicio do download do arquivo ..\\data\\01-collected\\201906_Compras.zip\n",
      "2020-01-03 09:26:48.494411: URL encontrada, fazendo o download do arquivo: ..\\data\\01-collected\\201906_Compras.zip\n",
      "2020-01-03 09:26:49.067815: Descompactando o arquivo ..\\data\\01-collected\\201906_Compras.zip\n",
      "2020-01-03 09:26:49.104734: Fim do download do arquivo ..\\data\\01-collected\\201906_Compras.zip\n",
      "2020-01-03 09:26:49.104734: Inicio do download do arquivo ..\\data\\01-collected\\201907_Compras.zip\n",
      "2020-01-03 09:26:50.679407: URL encontrada, fazendo o download do arquivo: ..\\data\\01-collected\\201907_Compras.zip\n",
      "2020-01-03 09:26:51.267689: Descompactando o arquivo ..\\data\\01-collected\\201907_Compras.zip\n",
      "2020-01-03 09:26:51.308115: Fim do download do arquivo ..\\data\\01-collected\\201907_Compras.zip\n",
      "2020-01-03 09:26:51.308279: Inicio do download do arquivo ..\\data\\01-collected\\201908_Compras.zip\n",
      "2020-01-03 09:26:53.028301: URL encontrada, fazendo o download do arquivo: ..\\data\\01-collected\\201908_Compras.zip\n",
      "2020-01-03 09:26:53.945238: Descompactando o arquivo ..\\data\\01-collected\\201908_Compras.zip\n",
      "2020-01-03 09:26:53.984186: Fim do download do arquivo ..\\data\\01-collected\\201908_Compras.zip\n",
      "2020-01-03 09:26:53.984950: Inicio do download do arquivo ..\\data\\01-collected\\201909_Compras.zip\n",
      "2020-01-03 09:26:55.767208: URL encontrada, fazendo o download do arquivo: ..\\data\\01-collected\\201909_Compras.zip\n",
      "2020-01-03 09:26:56.280175: Descompactando o arquivo ..\\data\\01-collected\\201909_Compras.zip\n",
      "2020-01-03 09:26:56.314372: Fim do download do arquivo ..\\data\\01-collected\\201909_Compras.zip\n",
      "2020-01-03 09:26:56.315051: Inicio do download do arquivo ..\\data\\01-collected\\201910_Compras.zip\n",
      "2020-01-03 09:26:57.970033: URL encontrada, fazendo o download do arquivo: ..\\data\\01-collected\\201910_Compras.zip\n",
      "2020-01-03 09:26:58.558069: Descompactando o arquivo ..\\data\\01-collected\\201910_Compras.zip\n",
      "2020-01-03 09:26:58.596178: Fim do download do arquivo ..\\data\\01-collected\\201910_Compras.zip\n",
      "2020-01-03 09:26:58.596178: Inicio do download do arquivo ..\\data\\01-collected\\201911_Compras.zip\n",
      "2020-01-03 09:27:00.655946: URL encontrada, fazendo o download do arquivo: ..\\data\\01-collected\\201911_Compras.zip\n",
      "2020-01-03 09:27:01.257770: Descompactando o arquivo ..\\data\\01-collected\\201911_Compras.zip\n",
      "2020-01-03 09:27:01.296947: Fim do download do arquivo ..\\data\\01-collected\\201911_Compras.zip\n",
      "2020-01-03 09:27:01.297077: Inicio do download do arquivo ..\\data\\01-collected\\201912_Compras.zip\n",
      "2020-01-03 09:27:02.221558: URL encontrada, fazendo o download do arquivo: ..\\data\\01-collected\\201912_Compras.zip\n",
      "2020-01-03 09:27:02.767561: Descompactando o arquivo ..\\data\\01-collected\\201912_Compras.zip\n",
      "2020-01-03 09:27:02.806671: Fim do download do arquivo ..\\data\\01-collected\\201912_Compras.zip\n",
      "2020-01-03 09:27:02.806866: Coleta dos arquivos finalizada.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Coleta os dados de Contratos do Governo Federal (Contratos). \n",
    "    Origem: Portal da Transparencia\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepara o dicionario de variaveis (kwargs = keyworded arguments)\n",
    "    kwargs = {}\n",
    "    \n",
    "    # Datas de Inicio e Fim (YYYY-MM-DD) \n",
    "    # Obs.: Dados disponiveis a partir de 2013-01-01\n",
    "    kwargs['dt_ini_ref'] = datetime.strptime('2019-01-01', \"%Y-%m-%d\")\n",
    "    kwargs['dt_fim_ref'] = datetime.strptime('2019-12-01', \"%Y-%m-%d\")\n",
    "    \n",
    "    # Coleta os arquivos\n",
    "    collect_data(**kwargs)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
