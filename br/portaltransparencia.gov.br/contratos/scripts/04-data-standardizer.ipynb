{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import codecs\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_date(date_reference):\n",
    "    \"\"\"\n",
    "    Funcao que recebe o ano (YYYY), ano e mes (YYYYmm) ou ano, mes e dia (YYYYmmdd)\n",
    "    no tipo string e o transforma no tipo date.\n",
    "    \n",
    "    Args:\n",
    "        date_reference(str): Ano, ano e mes ou ano, mes e dia.\n",
    "            Ex.: '2011' ou '201105' ou '20110526'\n",
    "    \n",
    "    Returns:\n",
    "        date: Data de referencia no formato YYYY-mm-dd.\n",
    "            Ex.: '2011-05-26'\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define o ano, mes e dia de referencia do arquivo\n",
    "    if len(date_reference) == 4:\n",
    "        year = date_reference[:4]\n",
    "        month = '01'\n",
    "        day = '01'\n",
    "    elif len(date_reference) == 6:\n",
    "        year = date_reference[:4]\n",
    "        month = date_reference[4:6]\n",
    "        day = '01'\n",
    "    elif len(date_reference) == 8:\n",
    "        year = date_reference[:4]\n",
    "        month = date_reference[4:6]\n",
    "        day = date_reference[6:]\n",
    "    \n",
    "    # Define a data de referencia do arquivo\n",
    "    date = pd.to_datetime(year+'-'+month+'-'+day)\n",
    "    \n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_references(data_file):\n",
    "    \"\"\"\n",
    "    Funcao que recebe o nome do arquivo original e extrai o assunto e\n",
    "    data de referencia.\n",
    "    \n",
    "    Args:\n",
    "        data_file(str): Nome do arquivo original.\n",
    "            Ex.: '201101_GastosDiretos.csv'\n",
    "    \n",
    "    Returns:\n",
    "        date: Data de referencia do arquivo.\n",
    "            Ex.: '2011-01-01'\n",
    "        string: Assunto de referencia do arquivo.\n",
    "            Ex.: 'GastosDiretos'\n",
    "    \"\"\"\n",
    "    # Expressao Regular para:\n",
    "    # Identificar a data de referencia no nome do arquivo\n",
    "    date_reference_re = re.compile(r'^[0-9]+')\n",
    "    # Identificar o assunto no nome do arquivo\n",
    "    file_subject_re = re.compile(r'_([\\w]+)\\.')\n",
    "    \n",
    "    # Identifica a data de referencia do arquivo\n",
    "    date_reference = re.search(date_reference_re, data_file).group()\n",
    "        \n",
    "    # Define a data de referencia do arquivo\n",
    "    date = to_date(date_reference)\n",
    "    \n",
    "    # Define o assunto do arquivo\n",
    "    subject = re.search(file_subject_re, data_file).group(1)\n",
    "    \n",
    "    return date, subject\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(text):\n",
    "    \"\"\"\n",
    "    Funcao que recebe um texto (string) e o padroniza.\n",
    "    Os passos são:\n",
    "    1. Insere o termo SIGILOSO nos registros protegidos por sigilo.\n",
    "    2. Insere o termo INDISPONIVEL nos registros com detalhamento nao disponivel.\n",
    "    3. Remove espacos brancos extras no final dos registros.\n",
    "    \n",
    "    Args:\n",
    "        text(str): Texto de um registro do arquivo original.\n",
    "            Ex.: 'Texto com espacos extras    '\n",
    "    \n",
    "    Returns:\n",
    "        str: Texto padronizado.\n",
    "            Ex.: 'Texto com espacos extras'\n",
    "    \"\"\"\n",
    "    # Expressao regular que identifica campos protegidos por sigilo\n",
    "    confidential_re = re.compile(r'protegidas por sigilo')\n",
    "    unavailable_re = re.compile(r'Detalhamento das informa')\n",
    "    \n",
    "    if pd.isnull(text):\n",
    "        return text\n",
    "    else:\n",
    "        c = confidential_re.search(text)\n",
    "        i = unavailable_re.search(text)\n",
    "        if c:\n",
    "            return u'Sigiloso'\n",
    "        elif i:\n",
    "            return u'Indisponivel'\n",
    "        else:\n",
    "            return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_float(text):\n",
    "    \"\"\"\n",
    "    Funcao que recebe um campo de valor numerico com duas casas decimais\n",
    "    no tipo string e o tranforma no tipo float.\n",
    "    Os passos sao:\n",
    "    1. Remove qualquer caractere nao numerico;\n",
    "    2. Transforma no tipo de dado float;\n",
    "    3. Divide por 100 para separar as casas decimais;\n",
    "    \n",
    "    Args:\n",
    "        text(str): Valor numerico em tipo string.\n",
    "            Ex.: '1.500,70'\n",
    "\n",
    "    Returns:\n",
    "        float: Valor numerico em tipo float.\n",
    "            Ex.: 1500.70\n",
    "    \"\"\"\n",
    "    # Expressao regular que identifica caracteres não numericos\n",
    "    only_number_re = re.compile(r'\\D')\n",
    "    \n",
    "    if pd.isnull(text):\n",
    "        return text\n",
    "    elif re.sub(only_number_re, '', text) == '':\n",
    "        return ''\n",
    "    else:\n",
    "        return float(re.sub(only_number_re, '', text))/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_date(text, date_reference):\n",
    "    \"\"\"\n",
    "    Funcao que recebe um campo de data no tipo string no formato dd/mm/YYYY\n",
    "    e o tranforma no tipo date. Se nao for um campo data, é retornada a data\n",
    "    de referencia do arquivo (para casos de campos sigilosos).\n",
    "    \n",
    "    Args:\n",
    "        text(str): Data em tipo string no formato dd/mm/YYYY.\n",
    "            Ex.: '15/07/2013'\n",
    "        date_reference(date): Data de referencia do arquivo origial.\n",
    "            Ex.: '2013-07-01'\n",
    "    Returns:\n",
    "        date: Data em tipo date no formato YYYY-mm-dd.\n",
    "            Ex.: '2013-07-15'\n",
    "    \"\"\"\n",
    "    # Expressao regular que identifica data no padrão dd/mm/YYYY\n",
    "    only_date_re = re.compile(r'([0-9]{2}\\/[0-9]{2}\\/[0-9]{4})')\n",
    "    \n",
    "    d = only_date_re.search(str(text))\n",
    "    if d:\n",
    "        return pd.to_datetime(text, format='%d/%m/%Y')\n",
    "    else:\n",
    "        return date_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_frame(in_fields, in_data_path):\n",
    "    \"\"\"\n",
    "    Funcao que recebe o caminho completo de um arquivo de dados ja codificado\n",
    "    em UTF-8, prepara-o em um data frame e renomeia as colunas.\n",
    "    \n",
    "    Args:\n",
    "        in_fields(array): Lista com os nomes das colunas para o data frame.\n",
    "            Ex.: ['cd_campo', 'nm_campo', 'dt_campo', 'vl_campo']\n",
    "        in_data_path(str): Caminho completo de acesso ao arquivo de dados.\n",
    "            Ex.: '..\\\\data\\\\encoded\\\\201301_GastosDiretos.csv'\n",
    "        \n",
    "    Returns:\n",
    "        dataframe: Data frame do arquivo original com as colunas renomeadas.\n",
    "    \"\"\"\n",
    "    # Le o arquivo original em um dataframe\n",
    "    df = pd.read_csv(in_data_path\n",
    "                    ,sep=';'\n",
    "                    ,quotechar = '\\\"'\n",
    "                    #,quoting = csv.QUOTE_NONE\n",
    "                    ,low_memory = False\n",
    "                    ,encoding = 'utf-8'\n",
    "                    ,dtype = 'object')\n",
    "    \n",
    "    #Renomeia as colunas\n",
    "    df.columns = in_fields\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_frame_to_csv(df, out_data_path):\n",
    "    \"\"\"\n",
    "    Funcao que recebe o caminho completo para escrita do dataframe e o\n",
    "    transforma em arquivo CSV, codificado em UTF-8 e separado por tab.\n",
    "    \n",
    "    Args:\n",
    "        df(dataframe): Dataframe com os campos padronizados.\n",
    "        out_data_path(str): Caminho completo para escrita do dataframe em csv.\n",
    "            Ex.: '..\\\\data\\\\padronized\\\\Favorecidos_GastosDiretos_2013-01-01.csv'\n",
    "    \"\"\"\n",
    "    df.to_csv(path_or_buf = out_data_path\n",
    "             ,index = False\n",
    "             ,sep = '\\t'\n",
    "             ,encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_fields(df, fields_list):\n",
    "    \"\"\"\n",
    "    Funcao que recebe um data frame e retorna uma copia com apenas as\n",
    "    colunas informadas.\n",
    "    \n",
    "    Args:\n",
    "        df(dataframe): Data frame enviado para recorte.\n",
    "        fields_list(array): Lista de colunas do dataframe para selecao.\n",
    "        \n",
    "    Returns:\n",
    "        dataframe: Copia do dataframe apenas com as colunas informadas.\n",
    "    \"\"\"\n",
    "    return df.loc[:,fields_list].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_data_source_fields(df, **kwargs):\n",
    "    \"\"\"\n",
    "    Funcao que adiciona ao final do dataframe uma sequencia de campos\n",
    "    referentes a fonte dos dados que o originou.\n",
    "    \n",
    "    Args:\n",
    "        df(dataframe): Dataframe com os campos padronizados.\n",
    "        date_reference(date): Data de referencia do arquivo original.\n",
    "            Ex.: '2013-01-01'\n",
    "        data_source(str): Nome da fonte do arquivo original.\n",
    "            Ex.: 'Portal da Transparência'\n",
    "        data_file(str): Nome do arquivo original.\n",
    "            Ex,: 'GastosDiretos_201301.csv'\n",
    "        \n",
    "    Returns:\n",
    "        dataframe: Dataframe com os campos referentes a \n",
    "            fonte de dados adicionado.\n",
    "    \"\"\"\n",
    "    df['dt_referencia'] = kwargs['date_reference']\n",
    "    df['nm_fonte_dados'] = kwargs['data_source']\n",
    "    df['nm_arquivo_dados'] = kwargs['data_file'] \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_compras(**kwargs):\n",
    "    \"\"\"\n",
    "    Recebe a localizacao fisica do arquivo organizado, renomeia as colunas, padroniza os tipos \n",
    "    de dados (texto, numerico e data) e cria um novo arquivo padronizado no local informado.\n",
    "    \n",
    "    Args:\n",
    "        data_file(str): Nome do arquivo original.\n",
    "            Ex.: '201001_CPGF.csv'\n",
    "        date_reference(date): Data de referencia do arquivo original.\n",
    "            Ex.: '2010-01-01'\n",
    "        in_data_path(str): Caminho completo para acesso ao arquivo original.\n",
    "            Ex.: '..\\data\\03-organized\\201001_CPGF.csv'\n",
    "        out_data_path(str): Caminho completo onde deve ser criado o(s) novo(s)\n",
    "            arquivo(s) com os dados padronizados.\n",
    "            Ex.: '..\\data\\04-standardized\\201001_CPGF.csv'\n",
    "    \"\"\"\n",
    "        \n",
    "    # Nome das colunas que irao substituir o nome das colunas originais\n",
    "    kwargs['in_fields'] = ['nr_contrato'\n",
    "                          ,'ds_objeto'\n",
    "                          ,'ds_fundamento_legal'\n",
    "                          ,'ds_modalidade_compra'\n",
    "                          ,'ds_situacao_contrato'\n",
    "                          ,'cd_orgao_superior'\n",
    "                          ,'nm_orgao_superior'\n",
    "                          ,'cd_orgao_subordinado'\n",
    "                          ,'nm_orgao_subordinado'\n",
    "                          ,'cd_unidade_gestora'\n",
    "                          ,'nm_unidade_gestora'\n",
    "                          ,'dt_assinatura_contrato'\n",
    "                          ,'dt_publicacao_dou'\n",
    "                          ,'dt_ini_vigencia'\n",
    "                          ,'dt_fim_vigencia'\n",
    "                          ,'nr_cnpj_contratado'\n",
    "                          ,'nm_contratado'\n",
    "                          ,'vl_inicial_compra'\n",
    "                          ,'vl_final_compra']\n",
    "    \n",
    "    # Prepara o CSV original em um dataframe e renomeia as colunas \n",
    "    df = load_data_frame(kwargs['in_fields'], kwargs['in_data_path'])\n",
    "    \n",
    "    # Padroniza todos os campos do dataframe\n",
    "    df = df.applymap(lambda x: clean_string(x))\n",
    "    \n",
    "    # Padroniza os campos de data e numericos\n",
    "    df['dt_assinatura_contrato'] = df['dt_assinatura_contrato'].apply(lambda x: clean_date(x, kwargs['date_reference']))\n",
    "    df['dt_publicacao_dou'] = df['dt_publicacao_dou'].apply(lambda x: clean_date(x, kwargs['date_reference']))\n",
    "    df['dt_ini_vigencia'] = df['dt_ini_vigencia'].apply(lambda x: clean_date(x, kwargs['date_reference']))\n",
    "    df['dt_fim_vigencia'] = df['dt_fim_vigencia'].apply(lambda x: clean_date(x, kwargs['date_reference']))\n",
    "    \n",
    "    df['vl_inicial_compra'] = df['vl_inicial_compra'].apply(clean_float)\n",
    "    df['vl_final_compra'] = df['vl_final_compra'].apply(clean_float)\n",
    "    \n",
    "    # Inclui os campos de informacao da fonte dos dados\n",
    "    df = add_data_source_fields(df, **kwargs)\n",
    "    \n",
    "    # Nome das colunas que irao substituir o nome das colunas originais\n",
    "    kwargs['out_fields'] = ['nr_contrato'\n",
    "                           ,'ds_objeto'\n",
    "                           ,'ds_fundamento_legal'\n",
    "                           ,'ds_modalidade_compra'\n",
    "                           ,'ds_situacao_contrato'\n",
    "                           ,'cd_orgao_superior'\n",
    "                           ,'nm_orgao_superior'\n",
    "                           ,'cd_orgao_subordinado'\n",
    "                           ,'nm_orgao_subordinado'\n",
    "                           ,'cd_unidade_gestora'\n",
    "                           ,'nm_unidade_gestora'\n",
    "                           ,'dt_assinatura_contrato'\n",
    "                           ,'dt_publicacao_dou'\n",
    "                           ,'dt_ini_vigencia'\n",
    "                           ,'dt_fim_vigencia'\n",
    "                           ,'nr_cnpj_contratado'\n",
    "                           ,'nm_contratado'\n",
    "                           ,'vl_inicial_compra'\n",
    "                           ,'vl_final_compra'\n",
    "                           ,'dt_referencia'\n",
    "                           ,'nm_fonte_dados'\n",
    "                           ,'nm_arquivo_dados']\n",
    "    \n",
    "    # Prepara um data frame com apenas as colunas do arquivo de saida\n",
    "    sub_df = select_fields(df, kwargs['out_fields'])\n",
    "    \n",
    "    # Salva o arquivo de saida no local informado\n",
    "    data_frame_to_csv(sub_df, kwargs['out_data_path'])\n",
    "\n",
    "    # Log: Mensagem de fim do processo\n",
    "    print(str(datetime.now()) + ': Arquivo ' + kwargs['data_file'] + ' padronizado.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_files():\n",
    "    \"\"\"\n",
    "    Acessa os arquivos da pasta 03-organized, passa pelo processo de padronizacao\n",
    "    e armazena-os na pasta 04-standardized.\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepara o dicionario de variaveis (kwargs = keyworded arguments)\n",
    "    kwargs = {}\n",
    "    \n",
    "    # Nome da fonte dos dados\n",
    "    kwargs['data_source'] = u'Portal da Transparência'\n",
    "    \n",
    "    # Diretorio de armazenamento dos arquivos originais\n",
    "    kwargs['in_data_dir'] = '..\\\\data\\\\03-organized'\n",
    "    \n",
    "    # Diretorio de armazenamento dos arquivos tratados\n",
    "    kwargs['out_data_dir'] = '..\\\\data\\\\04-standardized'\n",
    "    \n",
    "    # Lista dos arquivos organizados \n",
    "    kwargs['data_files'] = os.listdir(kwargs['in_data_dir'])\n",
    "    \n",
    "    # Log: Mensagem de inicio do processo\n",
    "    print(str(datetime.now()) + ': Padronizacao dos arquivos iniciada.')\n",
    "    \n",
    "    # Para cada arquivo na lista de arquivos organizados\n",
    "    for file in kwargs['data_files']:\n",
    "        \n",
    "        # Define o nome do arquivo\n",
    "        kwargs['data_file'] = file\n",
    "\n",
    "        # Define o caminho completo de acesso ao arquivo original\n",
    "        kwargs['in_data_path'] = os.path.join(kwargs['in_data_dir'], kwargs['data_file'])\n",
    "\n",
    "        # Define o caminho completo de armazenamento do arquivo padronizado\n",
    "        kwargs['out_data_path'] = os.path.join(kwargs['out_data_dir'], kwargs['data_file'])\n",
    "        \n",
    "        # Define data e assunto de referencia do arquivo\n",
    "        kwargs['date_reference'], kwargs['subject'] = file_references(kwargs['data_file'])\n",
    "\n",
    "        # Padroniza os arquivos\n",
    "        if kwargs['subject'] == 'Compras':\n",
    "            standardize_compras(**kwargs)   \n",
    "            \n",
    "      \n",
    "    # Log: Mensagem de finalizacao do processo\n",
    "    print(str(datetime.now()) + ': Padronizacao dos arquivos finalizada.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-04 07:06:02.925296: Padronizacao dos arquivos iniciada.\n",
      "2019-09-04 07:06:04.956434: Arquivo 201301_Compras.csv padronizado.\n",
      "2019-09-04 07:06:06.330336: Arquivo 201302_Compras.csv padronizado.\n",
      "2019-09-04 07:06:07.804394: Arquivo 201303_Compras.csv padronizado.\n",
      "2019-09-04 07:06:09.323906: Arquivo 201304_Compras.csv padronizado.\n",
      "2019-09-04 07:06:10.928125: Arquivo 201305_Compras.csv padronizado.\n",
      "2019-09-04 07:06:12.568938: Arquivo 201306_Compras.csv padronizado.\n",
      "2019-09-04 07:06:14.369121: Arquivo 201307_Compras.csv padronizado.\n",
      "2019-09-04 07:06:15.891565: Arquivo 201308_Compras.csv padronizado.\n",
      "2019-09-04 07:06:17.472860: Arquivo 201309_Compras.csv padronizado.\n",
      "2019-09-04 07:06:19.162333: Arquivo 201310_Compras.csv padronizado.\n",
      "2019-09-04 07:06:21.002412: Arquivo 201311_Compras.csv padronizado.\n",
      "2019-09-04 07:06:23.279403: Arquivo 201312_Compras.csv padronizado.\n",
      "2019-09-04 07:06:25.445613: Arquivo 201401_Compras.csv padronizado.\n",
      "2019-09-04 07:06:27.213885: Arquivo 201402_Compras.csv padronizado.\n",
      "2019-09-04 07:06:28.652547: Arquivo 201403_Compras.csv padronizado.\n",
      "2019-09-04 07:06:30.250277: Arquivo 201404_Compras.csv padronizado.\n",
      "2019-09-04 07:06:31.972669: Arquivo 201405_Compras.csv padronizado.\n",
      "2019-09-04 07:06:33.560431: Arquivo 201406_Compras.csv padronizado.\n",
      "2019-09-04 07:06:35.202489: Arquivo 201407_Compras.csv padronizado.\n",
      "2019-09-04 07:06:36.954789: Arquivo 201408_Compras.csv padronizado.\n",
      "2019-09-04 07:06:38.792872: Arquivo 201409_Compras.csv padronizado.\n",
      "2019-09-04 07:06:40.772613: Arquivo 201410_Compras.csv padronizado.\n",
      "2019-09-04 07:06:42.537861: Arquivo 201411_Compras.csv padronizado.\n",
      "2019-09-04 07:06:45.025715: Arquivo 201412_Compras.csv padronizado.\n",
      "2019-09-04 07:06:46.738134: Arquivo 201501_Compras.csv padronizado.\n",
      "2019-09-04 07:06:47.985798: Arquivo 201502_Compras.csv padronizado.\n",
      "2019-09-04 07:06:49.313822: Arquivo 201503_Compras.csv padronizado.\n",
      "2019-09-04 07:06:50.571549: Arquivo 201504_Compras.csv padronizado.\n",
      "2019-09-04 07:06:51.766959: Arquivo 201505_Compras.csv padronizado.\n",
      "2019-09-04 07:06:52.907518: Arquivo 201506_Compras.csv padronizado.\n",
      "2019-09-04 07:06:54.345176: Arquivo 201507_Compras.csv padronizado.\n",
      "2019-09-04 07:06:55.717079: Arquivo 201508_Compras.csv padronizado.\n",
      "2019-09-04 07:06:56.928353: Arquivo 201509_Compras.csv padronizado.\n",
      "2019-09-04 07:06:58.214508: Arquivo 201510_Compras.csv padronizado.\n",
      "2019-09-04 07:06:59.653802: Arquivo 201511_Compras.csv padronizado.\n",
      "2019-09-04 07:07:01.480884: Arquivo 201512_Compras.csv padronizado.\n",
      "2019-09-04 07:07:02.635396: Arquivo 201601_Compras.csv padronizado.\n",
      "2019-09-04 07:07:03.913979: Arquivo 201602_Compras.csv padronizado.\n",
      "2019-09-04 07:07:05.089343: Arquivo 201603_Compras.csv padronizado.\n",
      "2019-09-04 07:07:06.318056: Arquivo 201604_Compras.csv padronizado.\n",
      "2019-09-04 07:07:07.466492: Arquivo 201605_Compras.csv padronizado.\n",
      "2019-09-04 07:07:08.708680: Arquivo 201606_Compras.csv padronizado.\n",
      "2019-09-04 07:07:10.124890: Arquivo 201607_Compras.csv padronizado.\n",
      "2019-09-04 07:07:11.534149: Arquivo 201608_Compras.csv padronizado.\n",
      "2019-09-04 07:07:12.790796: Arquivo 201609_Compras.csv padronizado.\n",
      "2019-09-04 07:07:13.920784: Arquivo 201610_Compras.csv padronizado.\n",
      "2019-09-04 07:07:15.570836: Arquivo 201611_Compras.csv padronizado.\n",
      "2019-09-04 07:07:17.718598: Arquivo 201612_Compras.csv padronizado.\n",
      "2019-09-04 07:07:19.542721: Arquivo 201701_Compras.csv padronizado.\n",
      "2019-09-04 07:07:20.733566: Arquivo 201702_Compras.csv padronizado.\n",
      "2019-09-04 07:07:21.943298: Arquivo 201703_Compras.csv padronizado.\n",
      "2019-09-04 07:07:22.903276: Arquivo 201704_Compras.csv padronizado.\n",
      "2019-09-04 07:07:24.142081: Arquivo 201705_Compras.csv padronizado.\n",
      "2019-09-04 07:07:25.459555: Arquivo 201706_Compras.csv padronizado.\n",
      "2019-09-04 07:07:26.642436: Arquivo 201707_Compras.csv padronizado.\n",
      "2019-09-04 07:07:27.929460: Arquivo 201708_Compras.csv padronizado.\n",
      "2019-09-04 07:07:29.147203: Arquivo 201709_Compras.csv padronizado.\n",
      "2019-09-04 07:07:30.433762: Arquivo 201710_Compras.csv padronizado.\n",
      "2019-09-04 07:07:31.793639: Arquivo 201711_Compras.csv padronizado.\n",
      "2019-09-04 07:07:33.739435: Arquivo 201712_Compras.csv padronizado.\n",
      "2019-09-04 07:07:35.203520: Arquivo 201801_Compras.csv padronizado.\n",
      "2019-09-04 07:07:36.448700: Arquivo 201802_Compras.csv padronizado.\n",
      "2019-09-04 07:07:37.706374: Arquivo 201803_Compras.csv padronizado.\n",
      "2019-09-04 07:07:38.925112: Arquivo 201804_Compras.csv padronizado.\n",
      "2019-09-04 07:07:40.094988: Arquivo 201805_Compras.csv padronizado.\n",
      "2019-09-04 07:07:41.253927: Arquivo 201806_Compras.csv padronizado.\n",
      "2019-09-04 07:07:42.553453: Arquivo 201807_Compras.csv padronizado.\n",
      "2019-09-04 07:07:44.012589: Arquivo 201808_Compras.csv padronizado.\n",
      "2019-09-04 07:07:45.208637: Arquivo 201809_Compras.csv padronizado.\n",
      "2019-09-04 07:07:46.749506: Arquivo 201810_Compras.csv padronizado.\n",
      "2019-09-04 07:07:48.255991: Arquivo 201811_Compras.csv padronizado.\n",
      "2019-09-04 07:07:50.255641: Arquivo 201812_Compras.csv padronizado.\n",
      "2019-09-04 07:07:51.713742: Arquivo 201901_Compras.csv padronizado.\n",
      "2019-09-04 07:07:52.878627: Arquivo 201902_Compras.csv padronizado.\n",
      "2019-09-04 07:07:53.796679: Arquivo 201903_Compras.csv padronizado.\n",
      "2019-09-04 07:07:54.770075: Arquivo 201904_Compras.csv padronizado.\n",
      "2019-09-04 07:07:54.943612: Arquivo 201905_Compras.csv padronizado.\n",
      "2019-09-04 07:07:54.968580: Arquivo 201906_Compras.csv padronizado.\n",
      "2019-09-04 07:07:54.968580: Padronizacao dos arquivos finalizada.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Padroniza os dados de Contratos do Governo Federal (Contratos).\n",
    "    Origem: Portal da Transparencia\n",
    "    \"\"\"\n",
    "    \n",
    "    ### Padroniza os arquivos\n",
    "    standardize_files()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
