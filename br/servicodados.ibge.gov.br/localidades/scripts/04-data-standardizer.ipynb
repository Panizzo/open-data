{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import codecs\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_date(date_reference):\n",
    "    \"\"\"\n",
    "    Funcao que recebe o ano (YYYY), ano e mes (YYYYmm) ou ano, mes e dia (YYYYmmdd)\n",
    "    no tipo string e o transforma no tipo date.\n",
    "    \n",
    "    Args:\n",
    "        date_reference(str): Ano, ano e mes ou ano, mes e dia.\n",
    "            Ex.: '2011' ou '201105' ou '20110526'\n",
    "    \n",
    "    Returns:\n",
    "        date: Data de referencia no formato YYYY-mm-dd.\n",
    "            Ex.: '2011-05-26'\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define o ano, mes e dia de referencia do arquivo\n",
    "    if len(date_reference) == 4:\n",
    "        year = date_reference[:4]\n",
    "        month = '01'\n",
    "        day = '01'\n",
    "    elif len(date_reference) == 6:\n",
    "        year = date_reference[:4]\n",
    "        month = date_reference[4:6]\n",
    "        day = '01'\n",
    "    elif len(date_reference) == 8:\n",
    "        year = date_reference[:4]\n",
    "        month = date_reference[4:6]\n",
    "        day = date_reference[6:]\n",
    "    \n",
    "    # Define a data de referencia do arquivo\n",
    "    date = pd.to_datetime(year+'-'+month+'-'+day)\n",
    "    \n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_references(data_file):\n",
    "    \"\"\"\n",
    "    Funcao que recebe o nome do arquivo original e extrai o assunto e\n",
    "    data de referencia.\n",
    "    \n",
    "    Args:\n",
    "        data_file(str): Nome do arquivo original.\n",
    "            Ex.: '201101_GastosDiretos.csv'\n",
    "    \n",
    "    Returns:\n",
    "        date: Data de referencia do arquivo.\n",
    "            Ex.: '2011-01-01'\n",
    "        string: Assunto de referencia do arquivo.\n",
    "            Ex.: 'GastosDiretos'\n",
    "    \"\"\"\n",
    "    # Expressao Regular para:\n",
    "    # Identificar a data de referencia no nome do arquivo\n",
    "    date_reference_re = re.compile(r'^[0-9]+')\n",
    "    # Identificar o assunto no nome do arquivo\n",
    "    file_subject_re = re.compile(r'_([\\w]+)\\.')\n",
    "    \n",
    "    # Identifica a data de referencia do arquivo\n",
    "    date_reference = re.search(date_reference_re, data_file).group()\n",
    "        \n",
    "    # Define a data de referencia do arquivo\n",
    "    date = to_date(date_reference)\n",
    "    \n",
    "    # Define o assunto do arquivo\n",
    "    subject = re.search(file_subject_re, data_file).group(1)\n",
    "    \n",
    "    return date, subject\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(text):\n",
    "    \"\"\"\n",
    "    Funcao que recebe um texto (string) e o padroniza.\n",
    "    Os passos são:\n",
    "    1. Insere o termo SIGILOSO nos registros protegidos por sigilo.\n",
    "    2. Insere o termo INDISPONIVEL nos registros com detalhamento nao disponivel.\n",
    "    3. Remove espacos brancos extras no final dos registros.\n",
    "    \n",
    "    Args:\n",
    "        text(str): Texto de um registro do arquivo original.\n",
    "            Ex.: 'Texto com espacos extras    '\n",
    "    \n",
    "    Returns:\n",
    "        str: Texto padronizado.\n",
    "            Ex.: 'Texto com espacos extras'\n",
    "    \"\"\"\n",
    "    # Expressao regular que identifica campos protegidos por sigilo\n",
    "    confidential_re = re.compile(r'protegidas por sigilo')\n",
    "    unavailable_re = re.compile(r'Detalhamento das informa')\n",
    "    \n",
    "    if pd.isnull(text):\n",
    "        return text\n",
    "    else:\n",
    "        c = confidential_re.search(text)\n",
    "        i = unavailable_re.search(text)\n",
    "        if c:\n",
    "            return u'Sigiloso'\n",
    "        elif i:\n",
    "            return u'Indisponivel'\n",
    "        else:\n",
    "            return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_float(text):\n",
    "    \"\"\"\n",
    "    Funcao que recebe um campo de valor numerico com duas casas decimais\n",
    "    no tipo string e o tranforma no tipo float.\n",
    "    Os passos sao:\n",
    "    1. Remove qualquer caractere nao numerico;\n",
    "    2. Transforma no tipo de dado float;\n",
    "    3. Divide por 100 para separar as casas decimais;\n",
    "    \n",
    "    Args:\n",
    "        text(str): Valor numerico em tipo string.\n",
    "            Ex.: '1.500,70'\n",
    "\n",
    "    Returns:\n",
    "        float: Valor numerico em tipo float.\n",
    "            Ex.: 1500.70\n",
    "    \"\"\"\n",
    "    # Expressao regular que identifica caracteres não numericos\n",
    "    only_number_re = re.compile(r'\\D')\n",
    "    \n",
    "    if pd.isnull(text):\n",
    "        return text\n",
    "    else:\n",
    "        return float(re.sub(only_number_re, '', text))/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_date(text, date_reference):\n",
    "    \"\"\"\n",
    "    Funcao que recebe um campo de data no tipo string no formato dd/mm/YYYY\n",
    "    e o tranforma no tipo date. Se nao for um campo data, é retornada a data\n",
    "    de referencia do arquivo (para casos de campos sigilosos).\n",
    "    \n",
    "    Args:\n",
    "        text(str): Data em tipo string no formato dd/mm/YYYY.\n",
    "            Ex.: '15/07/2013'\n",
    "        date_reference(date): Data de referencia do arquivo origial.\n",
    "            Ex.: '2013-07-01'\n",
    "    Returns:\n",
    "        date: Data em tipo date no formato YYYY-mm-dd.\n",
    "            Ex.: '2013-07-15'\n",
    "    \"\"\"\n",
    "    # Expressao regular que identifica data no padrão dd/mm/YYYY\n",
    "    only_date_re = re.compile(r'([0-9]{2}\\/[0-9]{2}\\/[0-9]{4})')\n",
    "    \n",
    "    d = only_date_re.search(str(text))\n",
    "    if d:\n",
    "        return pd.to_datetime(text, format='%d/%m/%Y')\n",
    "    else:\n",
    "        return date_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_frame(in_fields, in_data_path):\n",
    "    \"\"\"\n",
    "    Funcao que recebe o caminho completo de um arquivo de dados ja codificado\n",
    "    em UTF-8, prepara-o em um data frame e renomeia as colunas.\n",
    "    \n",
    "    Args:\n",
    "        in_fields(array): Lista com os nomes das colunas para o data frame.\n",
    "            Ex.: ['cd_campo', 'nm_campo', 'dt_campo', 'vl_campo']\n",
    "        in_data_path(str): Caminho completo de acesso ao arquivo de dados.\n",
    "            Ex.: '..\\\\data\\\\encoded\\\\201301_GastosDiretos.csv'\n",
    "        \n",
    "    Returns:\n",
    "        dataframe: Data frame do arquivo original com as colunas renomeadas.\n",
    "    \"\"\"\n",
    "    # Le o arquivo original em um dataframe\n",
    "    df = pd.read_csv(in_data_path\n",
    "                    ,sep=';'\n",
    "                    ,quotechar = '\\\"'\n",
    "                    #,quoting = csv.QUOTE_NONE\n",
    "                    ,low_memory = False\n",
    "                    ,encoding = 'utf-8'\n",
    "                    ,dtype = 'object')\n",
    "    \n",
    "    #Renomeia as colunas\n",
    "    df.columns = in_fields\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_frame_to_csv(df, out_data_path):\n",
    "    \"\"\"\n",
    "    Funcao que recebe o caminho completo para escrita do dataframe e o\n",
    "    transforma em arquivo CSV, codificado em UTF-8 e separado por tab.\n",
    "    \n",
    "    Args:\n",
    "        df(dataframe): Dataframe com os campos padronizados.\n",
    "        out_data_path(str): Caminho completo para escrita do dataframe em csv.\n",
    "            Ex.: '..\\\\data\\\\padronized\\\\Favorecidos_GastosDiretos_2013-01-01.csv'\n",
    "    \"\"\"\n",
    "    df.to_csv(path_or_buf = out_data_path\n",
    "             ,index = False\n",
    "             ,sep = '\\t'\n",
    "             ,encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_fields(df, fields_list):\n",
    "    \"\"\"\n",
    "    Funcao que recebe um data frame e retorna uma copia com apenas as\n",
    "    colunas informadas.\n",
    "    \n",
    "    Args:\n",
    "        df(dataframe): Data frame enviado para recorte.\n",
    "        fields_list(array): Lista de colunas do dataframe para selecao.\n",
    "        \n",
    "    Returns:\n",
    "        dataframe: Copia do dataframe apenas com as colunas informadas.\n",
    "    \"\"\"\n",
    "    return df.loc[:,fields_list].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_data_source_fields(df, **kwargs):\n",
    "    \"\"\"\n",
    "    Funcao que adiciona ao final do dataframe uma sequencia de campos\n",
    "    referentes a fonte dos dados que o originou.\n",
    "    \n",
    "    Args:\n",
    "        df(dataframe): Dataframe com os campos padronizados.\n",
    "        date_reference(date): Data de referencia do arquivo original.\n",
    "            Ex.: '2013-01-01'\n",
    "        data_source(str): Nome da fonte do arquivo original.\n",
    "            Ex.: 'Portal da Transparência'\n",
    "        data_file(str): Nome do arquivo original.\n",
    "            Ex,: 'GastosDiretos_201301.csv'\n",
    "        \n",
    "    Returns:\n",
    "        dataframe: Dataframe com os campos referentes a \n",
    "            fonte de dados adicionado.\n",
    "    \"\"\"\n",
    "    df['dt_referencia'] = kwargs['date_reference']\n",
    "    df['nm_fonte_dados'] = kwargs['data_source']\n",
    "    df['nm_arquivo_dados'] = kwargs['data_file'] \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_cpgf(**kwargs):\n",
    "    \"\"\"\n",
    "    Recebe a localizacao fisica do arquivo organizado, renomeia as colunas, padroniza os tipos \n",
    "    de dados (texto, numerico e data) e cria um novo arquivo padronizado no local informado.\n",
    "    \n",
    "    Args:\n",
    "        data_file(str): Nome do arquivo original.\n",
    "            Ex.: '201001_CPGF.csv'\n",
    "        date_reference(date): Data de referencia do arquivo original.\n",
    "            Ex.: '2010-01-01'\n",
    "        in_data_path(str): Caminho completo para acesso ao arquivo original.\n",
    "            Ex.: '..\\data\\03-organized\\201001_CPGF.csv'\n",
    "        out_data_path(str): Caminho completo onde deve ser criado o(s) novo(s)\n",
    "            arquivo(s) com os dados padronizados.\n",
    "            Ex.: '..\\data\\04-standardized\\201001_CPGF.csv'\n",
    "    \"\"\"\n",
    "        \n",
    "    # Nome das colunas que irao substituir o nome das colunas originais\n",
    "    kwargs['in_fields'] = ['cd_orgao_superior'\n",
    "                          ,'nm_orgao_superior'\n",
    "                          ,'cd_orgao_subordinado'\n",
    "                          ,'nm_orgao_subordinado'\n",
    "                          ,'cd_unidade_gestora'\n",
    "                          ,'nm_unidade_gestora'\n",
    "                          ,'nr_ano_extrato'\n",
    "                          ,'nr_mes_extrato'\n",
    "                          ,'nr_cpf_portador'\n",
    "                          ,'nm_portador'\n",
    "                          ,'nr_cpf_cnpj_favorecido'\n",
    "                          ,'nm_favorecido'\n",
    "                          ,'tp_transacao'\n",
    "                          ,'dt_transacao'\n",
    "                          ,'vl_transacao']\n",
    "    \n",
    "    # Prepara o CSV original em um dataframe e renomeia as colunas \n",
    "    df = load_data_frame(kwargs['in_fields'], kwargs['in_data_path'])\n",
    "    \n",
    "    # Padroniza todos os campos do dataframe\n",
    "    df = df.applymap(lambda x: clean_string(x))\n",
    "    \n",
    "    # Padroniza os campos de data e numericos\n",
    "    df['nr_mes_extrato'] = df['nr_mes_extrato'].astype(int).map(\"{:02}\".format)\n",
    "    df['nr_anomes_extrato'] = df['nr_ano_extrato']+df['nr_mes_extrato'] \n",
    "    df['dt_extrato'] = df['nr_anomes_extrato'].apply(to_date)\n",
    "    \n",
    "    df['dt_transacao'] = df['dt_transacao'].apply(lambda x: clean_date(x, kwargs['date_reference']))\n",
    "    df['vl_transacao'] = df['vl_transacao'].apply(clean_float)\n",
    "    \n",
    "    # Inclui os campos de informacao da fonte dos dados\n",
    "    df = add_data_source_fields(df, **kwargs)\n",
    "    \n",
    "    # Nome das colunas que irao substituir o nome das colunas originais\n",
    "    kwargs['out_fields'] = ['cd_orgao_superior'\n",
    "                           ,'nm_orgao_superior'\n",
    "                           ,'cd_orgao_subordinado'\n",
    "                           ,'nm_orgao_subordinado'\n",
    "                           ,'cd_unidade_gestora'\n",
    "                           ,'nm_unidade_gestora'\n",
    "                           ,'dt_extrato'\n",
    "                           ,'nr_cpf_portador'\n",
    "                           ,'nm_portador'\n",
    "                           ,'nr_cpf_cnpj_favorecido'\n",
    "                           ,'nm_favorecido'\n",
    "                           ,'tp_transacao'\n",
    "                           ,'dt_transacao'\n",
    "                           ,'vl_transacao'\n",
    "                           ,'dt_referencia'\n",
    "                           ,'nm_fonte_dados'\n",
    "                           ,'nm_arquivo_dados']\n",
    "    \n",
    "    # Prepara um data frame com apenas as colunas do arquivo de saida\n",
    "    sub_df = select_fields(df, kwargs['out_fields'])\n",
    "    \n",
    "    # Salva o arquivo de saida no local informado\n",
    "    data_frame_to_csv(sub_df, kwargs['out_data_path'])\n",
    "\n",
    "    # Log: Mensagem de fim do processo\n",
    "    print(str(datetime.now()) + ': Arquivo ' + kwargs['data_file'] + ' padronizado.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_files():\n",
    "    \"\"\"\n",
    "    Acessa os arquivos da pasta 03-organized, passa pelo processo de padronizacao\n",
    "    e armazena-os na pasta 04-standardized.\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepara o dicionario de variaveis (kwargs = keyworded arguments)\n",
    "    kwargs = {}\n",
    "    \n",
    "    # Nome da fonte dos dados\n",
    "    kwargs['data_source'] = u'Portal da Transparência'\n",
    "    \n",
    "    # Diretorio de armazenamento dos arquivos originais\n",
    "    kwargs['in_data_dir'] = '..\\\\data\\\\03-organized'\n",
    "    \n",
    "    # Diretorio de armazenamento dos arquivos tratados\n",
    "    kwargs['out_data_dir'] = '..\\\\data\\\\04-standardized'\n",
    "    \n",
    "    # Lista dos arquivos organizados \n",
    "    kwargs['data_files'] = os.listdir(kwargs['in_data_dir'])\n",
    "    \n",
    "    # Log: Mensagem de inicio do processo\n",
    "    print(str(datetime.now()) + ': Padronizacao dos arquivos iniciada.')\n",
    "    \n",
    "    # Para cada arquivo na lista de arquivos organizados\n",
    "    for file in kwargs['data_files']:\n",
    "        \n",
    "        # Define o nome do arquivo\n",
    "        kwargs['data_file'] = file\n",
    "\n",
    "        # Define o caminho completo de acesso ao arquivo original\n",
    "        kwargs['in_data_path'] = os.path.join(kwargs['in_data_dir'], kwargs['data_file'])\n",
    "\n",
    "        # Define o caminho completo de armazenamento do arquivo padronizado\n",
    "        kwargs['out_data_path'] = os.path.join(kwargs['out_data_dir'], kwargs['data_file'])\n",
    "        \n",
    "        # Define data e assunto de referencia do arquivo\n",
    "        kwargs['date_reference'], kwargs['subject'] = file_references(kwargs['data_file'])\n",
    "\n",
    "        # Padroniza os arquivos\n",
    "        standardize_cpgf(**kwargs)       \n",
    "      \n",
    "    # Log: Mensagem de finalizacao do processo\n",
    "    print(str(datetime.now()) + ': Padronizacao dos arquivos finalizada.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-20 07:37:15.162899: Padronizacao dos arquivos iniciada.\n",
      "2019-08-20 07:37:18.739281: Arquivo 201301_CPGF.csv padronizado.\n",
      "2019-08-20 07:37:19.365837: Arquivo 201302_CPGF.csv padronizado.\n",
      "2019-08-20 07:37:21.099644: Arquivo 201303_CPGF.csv padronizado.\n",
      "2019-08-20 07:37:24.003268: Arquivo 201304_CPGF.csv padronizado.\n",
      "2019-08-20 07:37:27.649390: Arquivo 201305_CPGF.csv padronizado.\n",
      "2019-08-20 07:37:30.437389: Arquivo 201306_CPGF.csv padronizado.\n",
      "2019-08-20 07:37:33.855519: Arquivo 201307_CPGF.csv padronizado.\n",
      "2019-08-20 07:37:37.330574: Arquivo 201308_CPGF.csv padronizado.\n",
      "2019-08-20 07:37:40.521738: Arquivo 201309_CPGF.csv padronizado.\n",
      "2019-08-20 07:37:43.940212: Arquivo 201310_CPGF.csv padronizado.\n",
      "2019-08-20 07:37:47.344763: Arquivo 201311_CPGF.csv padronizado.\n",
      "2019-08-20 07:37:50.566280: Arquivo 201312_CPGF.csv padronizado.\n",
      "2019-08-20 07:37:53.066993: Arquivo 201401_CPGF.csv padronizado.\n",
      "2019-08-20 07:37:53.562378: Arquivo 201402_CPGF.csv padronizado.\n",
      "2019-08-20 07:37:55.382499: Arquivo 201403_CPGF.csv padronizado.\n",
      "2019-08-20 07:37:57.764314: Arquivo 201404_CPGF.csv padronizado.\n",
      "2019-08-20 07:38:00.439096: Arquivo 201405_CPGF.csv padronizado.\n",
      "2019-08-20 07:38:03.339896: Arquivo 201406_CPGF.csv padronizado.\n",
      "2019-08-20 07:38:06.197011: Arquivo 201407_CPGF.csv padronizado.\n",
      "2019-08-20 07:38:08.786476: Arquivo 201408_CPGF.csv padronizado.\n",
      "2019-08-20 07:38:11.868043: Arquivo 201409_CPGF.csv padronizado.\n",
      "2019-08-20 07:38:14.842492: Arquivo 201410_CPGF.csv padronizado.\n",
      "2019-08-20 07:38:18.058938: Arquivo 201411_CPGF.csv padronizado.\n",
      "2019-08-20 07:38:21.469533: Arquivo 201412_CPGF.csv padronizado.\n",
      "2019-08-20 07:38:23.869976: Arquivo 201501_CPGF.csv padronizado.\n",
      "2019-08-20 07:38:24.202900: Arquivo 201502_CPGF.csv padronizado.\n",
      "2019-08-20 07:38:25.595838: Arquivo 201503_CPGF.csv padronizado.\n",
      "2019-08-20 07:38:28.089778: Arquivo 201504_CPGF.csv padronizado.\n",
      "2019-08-20 07:38:30.383440: Arquivo 201505_CPGF.csv padronizado.\n",
      "2019-08-20 07:38:32.920461: Arquivo 201506_CPGF.csv padronizado.\n",
      "2019-08-20 07:38:35.584032: Arquivo 201507_CPGF.csv padronizado.\n",
      "2019-08-20 07:38:37.914371: Arquivo 201508_CPGF.csv padronizado.\n",
      "2019-08-20 07:38:40.264392: Arquivo 201509_CPGF.csv padronizado.\n",
      "2019-08-20 07:38:42.607406: Arquivo 201510_CPGF.csv padronizado.\n",
      "2019-08-20 07:38:45.080701: Arquivo 201511_CPGF.csv padronizado.\n",
      "2019-08-20 07:38:47.886801: Arquivo 201512_CPGF.csv padronizado.\n",
      "2019-08-20 07:38:50.003576: Arquivo 201601_CPGF.csv padronizado.\n",
      "2019-08-20 07:38:50.297601: Arquivo 201602_CPGF.csv padronizado.\n",
      "2019-08-20 07:38:51.619322: Arquivo 201603_CPGF.csv padronizado.\n",
      "2019-08-20 07:38:53.906780: Arquivo 201604_CPGF.csv padronizado.\n",
      "2019-08-20 07:38:56.191602: Arquivo 201605_CPGF.csv padronizado.\n",
      "2019-08-20 07:38:58.515790: Arquivo 201606_CPGF.csv padronizado.\n",
      "2019-08-20 07:39:00.770090: Arquivo 201607_CPGF.csv padronizado.\n",
      "2019-08-20 07:39:03.198248: Arquivo 201608_CPGF.csv padronizado.\n",
      "2019-08-20 07:39:05.672989: Arquivo 201609_CPGF.csv padronizado.\n",
      "2019-08-20 07:39:08.019823: Arquivo 201610_CPGF.csv padronizado.\n",
      "2019-08-20 07:39:10.198807: Arquivo 201611_CPGF.csv padronizado.\n",
      "2019-08-20 07:39:12.599818: Arquivo 201612_CPGF.csv padronizado.\n",
      "2019-08-20 07:39:14.545251: Arquivo 201701_CPGF.csv padronizado.\n",
      "2019-08-20 07:39:14.853058: Arquivo 201702_CPGF.csv padronizado.\n",
      "2019-08-20 07:39:16.192892: Arquivo 201703_CPGF.csv padronizado.\n",
      "2019-08-20 07:39:18.283313: Arquivo 201704_CPGF.csv padronizado.\n",
      "2019-08-20 07:39:20.120886: Arquivo 201705_CPGF.csv padronizado.\n",
      "2019-08-20 07:39:22.511919: Arquivo 201706_CPGF.csv padronizado.\n",
      "2019-08-20 07:39:24.794349: Arquivo 201707_CPGF.csv padronizado.\n",
      "2019-08-20 07:39:26.782815: Arquivo 201708_CPGF.csv padronizado.\n",
      "2019-08-20 07:39:29.235627: Arquivo 201709_CPGF.csv padronizado.\n",
      "2019-08-20 07:39:31.612792: Arquivo 201710_CPGF.csv padronizado.\n",
      "2019-08-20 07:39:34.524766: Arquivo 201711_CPGF.csv padronizado.\n",
      "2019-08-20 07:39:37.864354: Arquivo 201712_CPGF.csv padronizado.\n",
      "2019-08-20 07:39:40.445295: Arquivo 201801_CPGF.csv padronizado.\n",
      "2019-08-20 07:39:41.534522: Arquivo 201802_CPGF.csv padronizado.\n",
      "2019-08-20 07:39:42.997461: Arquivo 201803_CPGF.csv padronizado.\n",
      "2019-08-20 07:39:45.454179: Arquivo 201804_CPGF.csv padronizado.\n",
      "2019-08-20 07:39:48.074591: Arquivo 201805_CPGF.csv padronizado.\n",
      "2019-08-20 07:39:50.379164: Arquivo 201806_CPGF.csv padronizado.\n",
      "2019-08-20 07:39:52.396467: Arquivo 201807_CPGF.csv padronizado.\n",
      "2019-08-20 07:39:54.262947: Arquivo 201808_CPGF.csv padronizado.\n",
      "2019-08-20 07:39:56.339462: Arquivo 201809_CPGF.csv padronizado.\n",
      "2019-08-20 07:39:58.558530: Arquivo 201810_CPGF.csv padronizado.\n",
      "2019-08-20 07:40:01.193637: Arquivo 201811_CPGF.csv padronizado.\n",
      "2019-08-20 07:40:03.738531: Arquivo 201812_CPGF.csv padronizado.\n",
      "2019-08-20 07:40:05.341548: Arquivo 201901_CPGF.csv padronizado.\n",
      "2019-08-20 07:40:05.710755: Arquivo 201902_CPGF.csv padronizado.\n",
      "2019-08-20 07:40:07.019570: Arquivo 201903_CPGF.csv padronizado.\n",
      "2019-08-20 07:40:08.615953: Arquivo 201904_CPGF.csv padronizado.\n",
      "2019-08-20 07:40:10.566761: Arquivo 201905_CPGF.csv padronizado.\n",
      "2019-08-20 07:40:12.732370: Arquivo 201906_CPGF.csv padronizado.\n",
      "2019-08-20 07:40:12.733367: Padronizacao dos arquivos finalizada.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Padroniza os dados de Cartao de Pagamento do Governo Federal (CPGF)\n",
    "    Origem: Portal da Transparencia\n",
    "    \"\"\"\n",
    "    \n",
    "    ### Padroniza os arquivos\n",
    "    standardize_files()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
